{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: Intro to Python & R for Data Analysis\n",
    "## Lecture: Webscraping with Anthony\n",
    "\n",
    "contact: as66284n@pace.edu\n",
    "\n",
    "Git: https://github.com/avspinelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Build a dataset of skate decks from: https://laborskateshop.com/\n",
    "\n",
    "## General structure for webscraping with BS:\n",
    "\n",
    "### 1. Scrapability\n",
    "The first thing we want to know is if BS can scrape what we want it to. BS is good for working with html, but cant deal with java\n",
    "### 2. Building variables using a point example\n",
    "If the website is scrapable, its best to start small and build up\n",
    "### 3. Building loops\n",
    "We then typically build a loop aroud this concept to flip through items and pull what we want from each\n",
    "### 4. Pagination (If needed)\n",
    "And lastly we often want to flip through pages of a website to collect more than kust the first page\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Scrapability\n",
    "\n",
    "Lets start by seeing if the website will allow us to scrape, by making a request to the page with the skate decks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Request\n",
    "url = 'https://laborskateshop.com/collections/decks?filter.v.availability=1&page=1'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get html from the link\n",
    "\n",
    "soup = bs(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#\n",
    "# 2. Building variables using a point example\n",
    "Most websites use containers which we can flip through and grab data from. They typically all have the same tag which makes them, easy to loop over. In our case, each containor has the tag:\n",
    "\n",
    "li class=\"grid__item\"\n",
    "\n",
    "So lets start by getting all the tags that have that structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .find_all()\n",
    "decks = soup.find_all('li',{'class':'grid__item'})\n",
    "\n",
    "# After we have all of them, its best to just use one container to create our variables from, since they all have the same structure\n",
    "deck = decks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li class=\"grid__item\">\n",
       "<link href=\"//cdn.shopify.com/s/files/1/0025/9925/6153/t/25/assets/component-rating.css?v=24573085263941240431663960143\" media=\"all\" rel=\"stylesheet\" type=\"text/css\">\n",
       "<div class=\"card-wrapper underline-links-hover\">\n",
       "<div class=\"card card--standard card--media\" style=\"--ratio-percent: 100%;\">\n",
       "<div class=\"card__inner color-background-2 ratio\" style=\"--ratio-percent: 100%;\"><div class=\"card__media\">\n",
       "<div class=\"media media--transparent media--hover-effect\">\n",
       "<img alt=\"Krooked Tom Knox Debut Secret Pro Skateboard Deck\" class=\"motion-reduce\" height=\"3024\" sizes=\"(min-width: 1400px) 317px, (min-width: 990px) calc((100vw - 130px) / 4), (min-width: 750px) calc((100vw - 120px) / 3), calc((100vw - 35px) / 2)\" src=\"//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=533\" srcset=\"//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=165 165w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=360 360w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=533 533w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=720 720w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=940 940w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336&amp;width=1066 1066w,//cdn.shopify.com/s/files/1/0025/9925/6153/products/IMG_2559.jpg?v=1678119336 3024w\" width=\"3024\"/></div>\n",
       "</div><div class=\"card__content\">\n",
       "<div class=\"card__information\">\n",
       "<h3 class=\"card__heading\">\n",
       "<a class=\"full-unstyled-link\" href=\"/products/krooked-tom-knox-debut-secret-pro-skateboard-deck?_pos=1&amp;_fid=e92eaf160&amp;_ss=c\">\n",
       "                Krooked Tom Knox Debut Secret Pro Skateboard Deck\n",
       "              </a>\n",
       "</h3>\n",
       "</div>\n",
       "<div class=\"card__badge bottom left\"></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"card__content\">\n",
       "<div class=\"card__information\">\n",
       "<h3 class=\"card__heading h5\">\n",
       "<a class=\"full-unstyled-link\" href=\"/products/krooked-tom-knox-debut-secret-pro-skateboard-deck?_pos=1&amp;_fid=e92eaf160&amp;_ss=c\">\n",
       "              Krooked Tom Knox Debut Secret Pro Skateboard Deck\n",
       "            </a>\n",
       "</h3>\n",
       "<div class=\"card-information\"><span class=\"caption-large light\"></span>\n",
       "<div class=\"price\">\n",
       "<div class=\"price__container\"><div class=\"price__regular\">\n",
       "<span class=\"visually-hidden visually-hidden--inline\">Regular price</span>\n",
       "<span class=\"price-item price-item--regular\">\n",
       "        $60.00 USD\n",
       "      </span>\n",
       "</div>\n",
       "<div class=\"price__sale\">\n",
       "<span class=\"visually-hidden visually-hidden--inline\">Regular price</span>\n",
       "<span>\n",
       "<s class=\"price-item price-item--regular\">\n",
       "</s>\n",
       "</span><span class=\"visually-hidden visually-hidden--inline\">Sale price</span>\n",
       "<span class=\"price-item price-item--sale price-item--last\">\n",
       "        $60.00 USD\n",
       "      </span>\n",
       "</div>\n",
       "<small class=\"unit-price caption hidden\">\n",
       "<span class=\"visually-hidden\">Unit price</span>\n",
       "<span class=\"price-item price-item--last\">\n",
       "<span></span>\n",
       "<span aria-hidden=\"true\">/</span>\n",
       "<span class=\"visually-hidden\"> per </span>\n",
       "<span>\n",
       "</span>\n",
       "</span>\n",
       "</small>\n",
       "</div></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"card__badge bottom left\"></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</link></li>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck # Looking inside each container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Variables to collect\n",
    "\n",
    "From each container, we want two variables:\n",
    "\n",
    "### 1. Price\n",
    "### 2. Link\n",
    "\n",
    "We want to get, clean, and store all of our variables by identifying the tags associated and extracting the good stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we see that price is stored here:\n",
    "# <span class=\"price-item price-item--regular\" data-uw-rm-sr=\"\">\n",
    "#         $60.00 USD\n",
    "#       </span>\n",
    "\n",
    "\n",
    "# Taking that we find the variable:\n",
    "# deck.find('span',{'class':'price-item price-item--regular'})\n",
    "\n",
    "# Then use the .get_text() method to get the text of the element: \n",
    "# deck.find('span',{'class':'price-item price-item--regular'}).get_text()\n",
    "\n",
    "# Then we use a bit of regex: re.findall(r'\\d+', STRING_HERE) to find all the numeric charecters\n",
    "# re.findall(r'\\d+',deck.find('span',{'class':'price-item price-item--regular'}).get_text())\n",
    "\n",
    "# Final variable\n",
    "price = re.findall(r'\\d+',deck.find('span',{'class':'price-item price-item--regular'}).get_text())[0]\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://laborskateshop.com//products/krooked-tom-knox-debut-secret-pro-skateboard-deck?_pos=1&amp;_fid=e92eaf160&amp;_ss=c'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The link is stored here\n",
    "# <a href=\"/products/krooked-tom-knox-debut-secret-pro-skateboard-deck?_pos=1&amp;_fid=c59c1ef1d&amp;_ss=c\" class=\"full-unstyled-link\" data-uw-rm-brl=\"false\">\n",
    "#              Krooked Tom Knox Debut Secret Pro Skateboard Deck\n",
    "#           </a>\n",
    "\n",
    "# First get it with:\n",
    "# deck.find('h3',{'class':'card__heading h5'})\n",
    "\n",
    "# We then put it in a string and split it by href to get the link\n",
    "# str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1]\n",
    "\n",
    "# Clean the gardbage\n",
    "# str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "\n",
    "# and adding the begining of the https so it is searchable:\n",
    "#'https://laborskateshop.com/'+str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "\n",
    "# Final variable\n",
    "link = 'https://laborskateshop.com/'+str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#\n",
    "# 3. Building loops\n",
    "Next thing we want to do is loop through our containors while grabbing our three variables form each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/krooked-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-jah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-dus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-kei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-joe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/girl-mike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/girl-sean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/girl-rick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/girl-tyle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/girl-cory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/chocolate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/fucking-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74</td>\n",
       "      <td>https://laborskateshop.com//products/fucking-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                               link\n",
       "0     60  https://laborskateshop.com//products/krooked-t...\n",
       "1     70  https://laborskateshop.com//products/hopps-ste...\n",
       "2     70  https://laborskateshop.com//products/hopps-jah...\n",
       "3     70  https://laborskateshop.com//products/hopps-dus...\n",
       "4     70  https://laborskateshop.com//products/hopps-kei...\n",
       "5     70  https://laborskateshop.com//products/hopps-joe...\n",
       "6     70  https://laborskateshop.com//products/hopps-mar...\n",
       "7     70  https://laborskateshop.com//products/hopps-big...\n",
       "8     60  https://laborskateshop.com//products/chocolate...\n",
       "9     60  https://laborskateshop.com//products/chocolate...\n",
       "10    60  https://laborskateshop.com//products/chocolate...\n",
       "11    60  https://laborskateshop.com//products/chocolate...\n",
       "12    60  https://laborskateshop.com//products/chocolate...\n",
       "13    60  https://laborskateshop.com//products/chocolate...\n",
       "14    60  https://laborskateshop.com//products/chocolate...\n",
       "15    60  https://laborskateshop.com//products/girl-mike...\n",
       "16    60  https://laborskateshop.com//products/girl-sean...\n",
       "17    60  https://laborskateshop.com//products/girl-rick...\n",
       "18    60  https://laborskateshop.com//products/girl-tyle...\n",
       "19    60  https://laborskateshop.com//products/girl-cory...\n",
       "20    60  https://laborskateshop.com//products/chocolate...\n",
       "21    60  https://laborskateshop.com//products/chocolate...\n",
       "22    70  https://laborskateshop.com//products/fucking-a...\n",
       "23    74  https://laborskateshop.com//products/fucking-a..."
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets again make the request here to make sure any manipulation we may have donr above isnt happening\n",
    "url = 'https://laborskateshop.com/collections/decks?filter.v.availability=1&page=1'\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'html.parser')\n",
    "decks = soup.find_all('li',{'class':'grid__item'})\n",
    "\n",
    "\n",
    "# first loop\n",
    "out = []    # create a empty list that we are going to append our data into\n",
    "for deck in decks:     # \"for each container in the list of containers\"\n",
    "    \n",
    "    # Getting all of our variables from \"item\"\n",
    "    price = re.findall(r'\\d+',deck.find('span',{'class':'price-item price-item--regular'}).get_text())[0]\n",
    "    link = 'https://laborskateshop.com/'+str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "    \n",
    "    data = {'price' : price,   # here we build the variables into a dictionary\n",
    "            'link' : link\n",
    "    }\n",
    "    \n",
    "    out.append(data) # and then append it to the empty dict\n",
    "pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pagination (If needed)\n",
    "\n",
    "Okay so great, we got one page of skate decks with their price and link. But thats kind of boring as its only 20 or so observations. To get mroe, we need to go to the next page of the website and keep collecting. most url's have a pagination feature we can manipulate to get the next page. In the case of labor.com, its the standard \"page=\":\n",
    "https://laborskateshop.com/collections/decks?filter.v.availability=1&page=1\n",
    "\n",
    "If we manipulate that, we can pass the loop diffrent pages and it will collect more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 Complete\n",
      "Page 2 Complete\n",
      "Page 3 Complete\n",
      "Page 4 Complete\n",
      "Total Time to Run: 10.87 Seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>link</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/krooked-t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-ste...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-jah...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-dus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/hopps-kei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>70</td>\n",
       "      <td>https://laborskateshop.com//products/its-viole...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/alltimers...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/snack-wil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>69</td>\n",
       "      <td>https://laborskateshop.com//products/nike-sb-z...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>https://laborskateshop.com//products/antihero-...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                               link  page\n",
       "0     60  https://laborskateshop.com//products/krooked-t...     1\n",
       "1     70  https://laborskateshop.com//products/hopps-ste...     1\n",
       "2     70  https://laborskateshop.com//products/hopps-jah...     1\n",
       "3     70  https://laborskateshop.com//products/hopps-dus...     1\n",
       "4     70  https://laborskateshop.com//products/hopps-kei...     1\n",
       "..   ...                                                ...   ...\n",
       "19    70  https://laborskateshop.com//products/its-viole...     4\n",
       "20    60  https://laborskateshop.com//products/alltimers...     4\n",
       "21    60  https://laborskateshop.com//products/snack-wil...     4\n",
       "22    69  https://laborskateshop.com//products/nike-sb-z...     4\n",
       "23    60  https://laborskateshop.com//products/antihero-...     4\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# outer loop\n",
    "page = 1   # create our page variable which we will increase at the end of the loop\n",
    "url = 'https://laborskateshop.com/collections/decks?filter.v.availability=1&page='  # We replaced the 'page=1' with just 'page=' because we are goign to cycle through pages\n",
    "final_data = [] # Outer dictionary which will hold the inners\n",
    "\n",
    "\n",
    "while page < 5:     # \"While our page variable is less than 5, continue to run\". If you dont change the page number at the bottom of the loop it will run forever. if that happnes just restart the kernal\n",
    "    url_get = url+str(page)    # URL Creation\n",
    "\n",
    "    response = requests.get(url_get)         # Make the request to get the html from the page\n",
    "    soup = bs(response.text, 'html.parser')            \n",
    "    decks = soup.find_all('li',{'class':'grid__item'})\n",
    "\n",
    "    \n",
    "    \n",
    "    # Inner Loop\n",
    "    out_inner = []\n",
    "    for deck in decks:\n",
    "        price = re.findall(r'\\d+',deck.find('span',{'class':'price-item price-item--regular'}).get_text())[0]\n",
    "        link = 'https://laborskateshop.com/'+str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "        data = {'price' : price,\n",
    "                'link' : link\n",
    "        }\n",
    "        out_inner.append(data)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Bottom half of outer loop\n",
    "    inner_data = pd.DataFrame(out_inner).assign(page = page)   # Create a DataFrame of out_inner and assign a page column which = page\n",
    "    final_data.append(inner_data)   # Append the inner data to the outer dictionary to save it when we create another inner_data with the next page\n",
    "    print('Page '+str(page)+' Complete')    #print statment telling us where the scraper is and on which page\n",
    "    page = page + 1    # Increases the page by one to get the next page at the top of the loop\n",
    "    time.sleep(2)   # Very important to not bombard the website, always put sleep times inbetweem requests if you dont want to get caught...\n",
    "    # End of outer loop\n",
    "    \n",
    "print('Total Time to Run: ' + str(round(time.time() - start_time,2))+' Seconds') # We use the time library to see how long the scraper takes\n",
    "df = pd.concat(final_data).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Try!\n",
    "\n",
    "## Alter the scraper below to collect the first 2 pages of Footware from:\n",
    "https://laborskateshop.com/collections/footwear?filter.v.availability=1&page=1\n",
    "\n",
    "### Varibales to Collect:\n",
    "1. Price of each shoe\n",
    "2. Link to each shoe\n",
    "3. Name of each shoe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# outer loop\n",
    "page = 1   # create our page variable which we will increase at the end of the loop\n",
    "url = 'https://laborskateshop.com/collections/decks?filter.v.availability=1&page='  # We replaced the 'page=1' with just 'page=' because we are going to cycle through pages\n",
    "final_data = [] # Outer dictionary which will hold the inners\n",
    "\n",
    "\n",
    "while page < 5:     # \"While our page variable is less than 5, continue to run\". If you dont change the page number at the bottom of the loop it will run forever. if that happnes just restart the kernal\n",
    "    url_get = url+str(page)    # URL Creation\n",
    "\n",
    "    response = requests.get(url_get)         # Make the request to get the html from the page\n",
    "    soup = bs(response.text, 'html.parser')            \n",
    "    decks = soup.find_all('li',{'class':'grid__item'})\n",
    "\n",
    "    \n",
    "    \n",
    "    # Inner Loop\n",
    "    out_inner = []\n",
    "    for deck in decks:\n",
    "        price = re.findall(r'\\d+',deck.find('span',{'class':'price-item price-item--regular'}).get_text())[0]\n",
    "        link = 'https://laborskateshop.com/'+str(deck.find('h3',{'class':'card__heading h5'})).split('href=\"')[1].split('\">\\n')[0]\n",
    "        data = {'price' : price,\n",
    "                'link' : link\n",
    "        }\n",
    "        out_inner.append(data)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Bottom half of outer loop\n",
    "    inner_data = pd.DataFrame(out_inner).assign(page = page)   # Create a DataFrame of out_inner and assign a page column which = page\n",
    "    final_data.append(inner_data)   # Append the inner data to the outer dictionary to save it when we create another inner_data with the next page\n",
    "    print('Page '+str(page)+' Complete')    #print statment telling us where the scraper is and on which page\n",
    "    page = page + 1    # Increases the page by one to get the next page at the top of the loop\n",
    "    time.sleep(2)   # Very important to not bombard the website, always put sleep times inbetweem requests if you dont want to get caught...\n",
    "    # End of outer loop\n",
    "    \n",
    "print('Total Time to Run: ' + str(round(time.time() - start_time,2))+' Seconds') # We use the time library to see how long the scraper takes\n",
    "df = pd.concat(final_data).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
